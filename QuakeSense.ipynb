{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NO3F_sOWAwoa",
        "outputId": "8873464f-4ac7-4ab8-9c0c-6d60c9082717"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.118.3)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.6)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly) (9.1.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio plotly requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timezone\n",
        "import os\n",
        "import plotly.express as px\n",
        "import gradio as gr\n",
        "\n",
        "USGS_DAY_URL = \"https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_day.geojson\"\n",
        "USGS_MONTH_URL = \"https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_month.geojson\"\n"
      ],
      "metadata": {
        "id": "NiC31pBzIC52"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_earthquake_data(url: str = USGS_DAY_URL) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Fetch earthquake data from USGS GeoJSON feed and return a clean DataFrame.\n",
        "    \"\"\"\n",
        "    resp = requests.get(url, timeout=10)\n",
        "    resp.raise_for_status()\n",
        "    data = resp.json()\n",
        "\n",
        "    records = []\n",
        "    for feature in data.get(\"features\", []):\n",
        "        props = feature.get(\"properties\", {})\n",
        "        geom = feature.get(\"geometry\", {})\n",
        "        coords = geom.get(\"coordinates\", [None, None, None])\n",
        "        lon, lat, depth_km = (coords + [None, None, None])[:3]\n",
        "\n",
        "        quake_time_ms = props.get(\"time\")\n",
        "        dt = datetime.fromtimestamp(quake_time_ms / 1000.0, tz=timezone.utc) if quake_time_ms else None\n",
        "\n",
        "        records.append({\n",
        "            \"time_utc\": dt,\n",
        "            \"magnitude\": props.get(\"mag\"),\n",
        "            \"place\": props.get(\"place\"),\n",
        "            \"longitude\": lon,\n",
        "            \"latitude\": lat,\n",
        "            \"depth_km\": depth_km,\n",
        "            \"tsunami_flag\": props.get(\"tsunami\"),\n",
        "            \"alert_level_raw\": props.get(\"alert\"),\n",
        "            \"felt_reports\": props.get(\"felt\"),\n",
        "            \"url\": props.get(\"url\")\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(records)\n",
        "    # Drop rows with missing mag / coords\n",
        "    df = df.dropna(subset=[\"magnitude\", \"latitude\", \"longitude\"]).reset_index(drop=True)\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "EjpXtrIXIGdv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_severity(mag: float) -> str:\n",
        "    if mag < 2.0:\n",
        "        return \"Micro\"\n",
        "    elif mag < 4.0:\n",
        "        return \"Minor\"\n",
        "    elif mag < 5.0:\n",
        "        return \"Light\"\n",
        "    elif mag < 6.0:\n",
        "        return \"Moderate\"\n",
        "    elif mag < 7.0:\n",
        "        return \"Strong\"\n",
        "    elif mag < 8.0:\n",
        "        return \"Major\"\n",
        "    else:\n",
        "        return \"Great\"\n",
        "\n",
        "\n",
        "def classify_depth(depth_km: float) -> str:\n",
        "    if depth_km is None:\n",
        "        return \"Unknown\"\n",
        "    if depth_km < 70:\n",
        "        return \"Shallow\"\n",
        "    elif depth_km < 300:\n",
        "        return \"Intermediate\"\n",
        "    else:\n",
        "        return \"Deep\"\n",
        "\n",
        "\n",
        "def extract_region(place: str) -> str:\n",
        "    if not isinstance(place, str):\n",
        "        return \"Unknown\"\n",
        "    parts = place.split(\",\")\n",
        "    if len(parts) > 1:\n",
        "        region = parts[-1].strip()\n",
        "    else:\n",
        "        region = place.strip()\n",
        "    return region if region else \"Unknown\"\n",
        "\n",
        "\n",
        "def compute_risk_score(mag: float, depth_km: float) -> float:\n",
        "    if depth_km is None or depth_km <= 0:\n",
        "        depth_km = 10.0\n",
        "    if depth_km < 70:\n",
        "        depth_factor = 1.3\n",
        "    elif depth_km < 300:\n",
        "        depth_factor = 1.1\n",
        "    else:\n",
        "        depth_factor = 0.9\n",
        "    return round(mag * depth_factor, 2)\n",
        "\n",
        "\n",
        "def enrich_earthquake_data(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    df[\"severity\"] = df[\"magnitude\"].apply(classify_severity)\n",
        "    df[\"depth_category\"] = df[\"depth_km\"].apply(classify_depth)\n",
        "    df[\"region\"] = df[\"place\"].apply(extract_region)\n",
        "    df[\"risk_score\"] = df.apply(lambda r: compute_risk_score(r[\"magnitude\"], r[\"depth_km\"]), axis=1)\n",
        "\n",
        "    def risk_label(score):\n",
        "        if score >= 7.0:\n",
        "            return \"Critical\"\n",
        "        elif score >= 5.5:\n",
        "            return \"High\"\n",
        "        elif score >= 4.0:\n",
        "            return \"Moderate\"\n",
        "        else:\n",
        "            return \"Low\"\n",
        "    df[\"risk_level\"] = df[\"risk_score\"].apply(risk_label)\n",
        "    df = df.sort_values(\"time_utc\", ascending=False).reset_index(drop=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "u_GHTWfQIJ1k"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def export_view_to_csv(df: pd.DataFrame, prefix: str = \"earthquakes_view\") -> str:\n",
        "    \"\"\"\n",
        "    Save DataFrame as CSV in /tmp and return the path.\n",
        "    \"\"\"\n",
        "    os.makedirs(\"/tmp\", exist_ok=True)\n",
        "    path = f\"/tmp/{prefix}.csv\"\n",
        "    df.to_csv(path, index=False)\n",
        "    return path"
      ],
      "metadata": {
        "id": "bRRUmkD5IQh4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_live_dashboard(\n",
        "    min_mag: float = 3.0,\n",
        "    region: str = \"All\",\n",
        "    sort_by: str = \"Newest\"\n",
        "):\n",
        "    # 1) Fetch + enrich\n",
        "    base_df = fetch_earthquake_data(USGS_DAY_URL)\n",
        "    df = enrich_earthquake_data(base_df)\n",
        "\n",
        "    # 2) Filter\n",
        "    df = df[df[\"magnitude\"] >= min_mag].copy()\n",
        "    if region != \"All\":\n",
        "        df = df[df[\"region\"] == region].copy()\n",
        "\n",
        "    # If nothing left after filtering\n",
        "    if df.empty:\n",
        "        summary_md = f\"### No earthquakes found for the selected filters in the last 24 hours.\"\n",
        "        alert_md = \"âœ… No major earthquakes (M â‰¥ 6.0) in current view.\"\n",
        "        fig = px.scatter(title=\"No data\")\n",
        "        empty_df = pd.DataFrame()\n",
        "        csv_path = export_view_to_csv(empty_df, prefix=\"earthquakes_empty_view\")\n",
        "        return summary_md, alert_md, fig, empty_df, csv_path\n",
        "\n",
        "    # 3) Summary text\n",
        "    total_quakes = len(df)\n",
        "    max_mag = df[\"magnitude\"].max()\n",
        "    # IMPORTANT: use loc (label), not iloc (position)\n",
        "    strongest = df.loc[df[\"magnitude\"].idxmax()]\n",
        "    strongest_place = strongest[\"place\"]\n",
        "    strongest_time = strongest[\"time_utc\"].strftime(\"%Y-%m-%d %H:%M:%S UTC\") if strongest[\"time_utc\"] else \"Unknown\"\n",
        "\n",
        "    risk_counts = df[\"risk_level\"].value_counts().to_dict()\n",
        "\n",
        "    summary_lines = [\n",
        "        f\"### Earthquake Summary (last 24 hours, mag â‰¥ {min_mag})\",\n",
        "        f\"- Total earthquakes: **{total_quakes}**\",\n",
        "        f\"- Strongest event: **M {max_mag:.1f}** near **{strongest_place}**\",\n",
        "        f\"- Time of strongest event: **{strongest_time}**\",\n",
        "        \"\",\n",
        "        \"#### Risk Level Distribution:\"\n",
        "    ]\n",
        "    for level in [\"Critical\", \"High\", \"Moderate\", \"Low\"]:\n",
        "        count = risk_counts.get(level, 0)\n",
        "        summary_lines.append(f\"- {level}: **{count}**\")\n",
        "    summary_md = \"\\n\".join(summary_lines)\n",
        "\n",
        "    # 4) Alert rule (M â‰¥ 6)\n",
        "    major_quakes = df[df[\"magnitude\"] >= 6.0]\n",
        "    if not major_quakes.empty:\n",
        "        strongest_major = major_quakes.loc[major_quakes[\"magnitude\"].idxmax()]\n",
        "        alert_md = (\n",
        "            f\"ðŸš¨ **Major earthquake detected!**\\n\\n\"\n",
        "            f\"- Max magnitude: **M {strongest_major['magnitude']:.1f}**\\n\"\n",
        "            f\"- Location: **{strongest_major['place']}**\\n\"\n",
        "            f\"- Time: **{strongest_major['time_utc']} (UTC)**\\n\\n\"\n",
        "            \"Review seismic activity and follow official emergency channels.\"\n",
        "        )\n",
        "    else:\n",
        "        alert_md = \"âœ… No major earthquakes (M â‰¥ 6.0) in current view.\"\n",
        "\n",
        "    # 5) Plot\n",
        "    df_plot = df.copy()\n",
        "    df_plot[\"time_str\"] = df_plot[\"time_utc\"].astype(str)\n",
        "    fig = px.scatter(\n",
        "        df_plot,\n",
        "        x=\"time_str\",\n",
        "        y=\"magnitude\",\n",
        "        size=\"risk_score\",\n",
        "        color=\"risk_level\",\n",
        "        hover_data=[\"place\", \"depth_km\", \"region\"],\n",
        "        title=\"Earthquake Magnitude Over Time (Bubble size = risk score)\",\n",
        "        labels={\"time_str\": \"Time (UTC)\", \"magnitude\": \"Magnitude\"}\n",
        "    )\n",
        "    fig.update_layout(xaxis_tickangle=-45)\n",
        "\n",
        "    # 6) Sort table\n",
        "    if sort_by == \"Newest\":\n",
        "        df_table = df.sort_values(\"time_utc\", ascending=False)\n",
        "    elif sort_by == \"Magnitude (Highâ†’Low)\":\n",
        "        df_table = df.sort_values(\"magnitude\", ascending=False)\n",
        "    elif sort_by == \"Risk (Highâ†’Low)\":\n",
        "        df_table = df.sort_values(\"risk_score\", ascending=False)\n",
        "    else:\n",
        "        df_table = df\n",
        "\n",
        "    df_table = df_table[[\n",
        "        \"time_utc\", \"magnitude\", \"severity\", \"region\",\n",
        "        \"depth_km\", \"depth_category\", \"risk_score\", \"risk_level\",\n",
        "        \"place\", \"url\"\n",
        "    ]].head(200)\n",
        "\n",
        "    csv_path = export_view_to_csv(df_table, prefix=\"earthquakes_live_view\")\n",
        "\n",
        "    return summary_md, alert_md, fig, df_table, csv_path"
      ],
      "metadata": {
        "id": "jxCdjb-sISAX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def top10_major_earthquakes_month():\n",
        "    \"\"\"\n",
        "    Top 10 strongest earthquakes in the last 30 days (by place/city/region).\n",
        "    \"\"\"\n",
        "    df_month = fetch_earthquake_data(USGS_MONTH_URL)\n",
        "    df_month = enrich_earthquake_data(df_month)\n",
        "\n",
        "    if df_month.empty:\n",
        "        return \"No data for this month.\", px.bar(title=\"No data\"), pd.DataFrame()\n",
        "\n",
        "    df_top = df_month.sort_values(\"magnitude\", ascending=False).head(10)\n",
        "    df_top = df_top[[\n",
        "        \"time_utc\", \"magnitude\", \"severity\", \"region\",\n",
        "        \"depth_km\", \"depth_category\", \"risk_score\", \"risk_level\",\n",
        "        \"place\", \"url\"\n",
        "    ]]\n",
        "\n",
        "    fig = px.bar(\n",
        "        df_top.sort_values(\"magnitude\"),\n",
        "        x=\"magnitude\",\n",
        "        y=\"place\",\n",
        "        orientation=\"h\",\n",
        "        color=\"risk_level\",\n",
        "        title=\"Top 10 Major Earthquakes (Last 30 Days)\",\n",
        "        labels={\"magnitude\": \"Magnitude\", \"place\": \"Location / City / Region\"}\n",
        "    )\n",
        "\n",
        "    return \"### Top 10 Major Earthquakes (Last 30 Days)\", fig, df_top"
      ],
      "metadata": {
        "id": "MWszJjTPIVTx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_region_choices():\n",
        "    df = enrich_earthquake_data(fetch_earthquake_data(USGS_DAY_URL))\n",
        "    regions = sorted(df[\"region\"].dropna().unique().tolist())\n",
        "    return [\"All\"] + regions"
      ],
      "metadata": {
        "id": "epJrAwKgIbGl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def live_callback(min_mag, region, sort_by):\n",
        "    return build_live_dashboard(min_mag=min_mag, region=region, sort_by=sort_by)\n",
        "\n",
        "def top10_callback():\n",
        "    return top10_major_earthquakes_month()\n",
        "\n",
        "\n",
        "with gr.Blocks(title=\"Real-Time Earthquake Alert & Analytics System\") as demo:\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        # QuakeSense â€“ Real-Time Seismic Analytics System\n",
        "        Live and recent analytics of global earthquakes.\n",
        "        *Data source: USGS Earthquake Hazards Program.*\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    with gr.Tab(\"Live Dashboard (24h)\"):\n",
        "        with gr.Row():\n",
        "            min_mag_slider = gr.Slider(0.0, 8.0, value=3.0, step=0.1, label=\"Minimum Magnitude\")\n",
        "            region_dropdown = gr.Dropdown(choices=[\"All\"], value=\"All\", label=\"Region (auto-filled)\")\n",
        "            sort_dropdown = gr.Dropdown(\n",
        "                choices=[\"Newest\", \"Magnitude (Highâ†’Low)\", \"Risk (Highâ†’Low)\"],\n",
        "                value=\"Newest\",\n",
        "                label=\"Sort Table By\"\n",
        "            )\n",
        "        refresh_btn = gr.Button(\"ðŸ”„ Refresh Data & Update Dashboard\")\n",
        "\n",
        "        alert_out = gr.Markdown(label=\"Alert\")\n",
        "        summary_out = gr.Markdown(label=\"Summary\")\n",
        "        plot_out = gr.Plot(label=\"Magnitude vs Time\")\n",
        "        table_out = gr.Dataframe(label=\"Earthquake Events\", interactive=False, wrap=True)\n",
        "        csv_out = gr.File(label=\"Download Filtered View (CSV)\")\n",
        "\n",
        "        # init region list on load\n",
        "        def init_regions():\n",
        "            return gr.update(choices=get_region_choices(), value=\"All\")\n",
        "\n",
        "        demo.load(init_regions, inputs=None, outputs=region_dropdown)\n",
        "\n",
        "        refresh_btn.click(\n",
        "            fn=live_callback,\n",
        "            inputs=[min_mag_slider, region_dropdown, sort_dropdown],\n",
        "            outputs=[summary_out, alert_out, plot_out, table_out, csv_out]\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"Top 10 Major Earthquakes (30 days)\"):\n",
        "        top10_btn = gr.Button(\"ðŸ”„ Load Top 10\")\n",
        "        top10_summary = gr.Markdown()\n",
        "        top10_plot = gr.Plot()\n",
        "        top10_table = gr.Dataframe(interactive=False, wrap=True)\n",
        "\n",
        "        top10_btn.click(\n",
        "            fn=top10_callback,\n",
        "            inputs=None,\n",
        "            outputs=[top10_summary, top10_plot, top10_table]\n",
        "        )\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "Fh4BiyA7Ie3o",
        "outputId": "84f576ca-ba55-4250-cb77-466030078ee5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a910be1189749ac26e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a910be1189749ac26e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QwOWs2dZI9DK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}